{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Spotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ryan Bales (@ryanbales)<br>ryan@balesofdata.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/2016_debates/\"\n",
    "transcription_data_path = \"{}{}\".format(data_path, \"transcripts/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file_list):\n",
    "    data = []\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            transcript = json.load(f)\n",
    "            data.append(transcript[\"results\"][\"transcripts\"][0][\"transcript\"])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Transcription Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"{}{}\".format(transcription_data_path, \"debate_1.mp3.json\"),\n",
    "    \"{}{}\".format(transcription_data_path, \"debate_2.mp3.json\"),\n",
    "    \"{}{}\".format(transcription_data_path, \"debate_3.mp3.json\"),\n",
    "    \"{}{}\".format(transcription_data_path, \"vp_debate.mp3.json\")\n",
    "]\n",
    "                       \n",
    "docs = get_text(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Documents (Remove Stop Words and Run Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "    clean_sentence_list = []\n",
    "    \n",
    "    for sentence in gensim.summarization.textcleaner.get_sentences(doc):\n",
    "        sentence_clean = gensim.parsing.preprocessing.remove_stopwords(sentence)\n",
    "        sentence_clean = gensim.parsing.preprocessing.stem_text(sentence_clean)\n",
    "        sentence_clean = gensim.parsing.preprocessing.strip_punctuation(sentence_clean)\n",
    "        sentence_clean = gensim.parsing.preprocessing.strip_multiple_whitespaces(sentence_clean)\n",
    "\n",
    "        clean_sentence_list.append(sentence_clean)\n",
    "    \n",
    "    processed_docs.append(clean_sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_phrase = \"taxes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Same Preporcessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tax'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = gensim.parsing.preprocessing.remove_stopwords(search_phrase)\n",
    "search_phrase = gensim.parsing.preprocessing.stem_text(search_phrase)\n",
    "search_phrase = gensim.parsing.preprocessing.strip_punctuation(search_phrase)\n",
    "search_phrase = gensim.parsing.preprocessing.strip_multiple_whitespaces(search_phrase)\n",
    "\n",
    "search_phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Keywords in each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def search_keyword(doc, search_phrase):\n",
    "    text = ' '.join(doc)\n",
    "    tokens = gensim.utils.tokenize(text)\n",
    "    return Counter(tokens)[search_phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 usages of 'tax' in document index 1\n",
      "Found 32 usages of 'tax' in document index 2\n",
      "Found 25 usages of 'tax' in document index 3\n",
      "Found 44 usages of 'tax' in document index 4\n"
     ]
    }
   ],
   "source": [
    "search_phrase_length = len(search_phrase.split())\n",
    "doc_index = 0\n",
    "\n",
    "for doc in processed_docs:\n",
    "    doc_index += 1\n",
    "    \n",
    "    if search_phrase_length == 1:\n",
    "        phrase_count = search_keyword(doc, search_phrase)  \n",
    "    else:\n",
    "        raise Exception(\"Unsupported Search Phrase\")\n",
    "    \n",
    "    print(\"Found {} usages of '{}' in document index {}\".format(phrase_count, search_phrase, doc_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
